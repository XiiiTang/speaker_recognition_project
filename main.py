"""
å£°çº¹è¯†åˆ«ç³»ç»Ÿä¸»ç¨‹åº

ä¸²è”æ‰€æœ‰æ¨¡å—å®ç°å®Œæ•´çš„è®­ç»ƒã€æ³¨å†Œå’Œæµ‹è¯•æµç¨‹ã€‚
æ”¯æŒDTWã€VQã€GMMä¸‰ç§ç®—æ³•çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚
"""

import os
import sys
import argparse
import time
from typing import Dict, List, Tuple
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from speaker_recognition.config import config
from speaker_recognition.data_loader import get_dataset_split, load_test_trials
from speaker_recognition.models import DTWModel, VQModel, GMMModel
from speaker_recognition.evaluate import (
    calculate_accuracy, calculate_eer, print_evaluation_report,
    plot_det_curve, plot_score_distribution
)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='å£°çº¹è¯†åˆ«ç³»ç»Ÿ')
    
    parser.add_argument('--model', type=str, choices=['dtw', 'vq', 'gmm'], 
                       default='gmm', help='é€‰æ‹©è¯†åˆ«ç®—æ³• (é»˜è®¤: gmm)')
    
    parser.add_argument('--mode', type=str, 
                       choices=['train', 'test', 'full'], default='full',
                       help='è¿è¡Œæ¨¡å¼: train(ä»…è®­ç»ƒ), test(ä»…æµ‹è¯•), full(å®Œæ•´æµç¨‹)')
    
    parser.add_argument('--data-path', type=str, default=None,
                       help='æ•°æ®é›†è·¯å¾„ (é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„)')
    
    parser.add_argument('--save-model', type=str, default=None,
                       help='æ¨¡å‹ä¿å­˜è·¯å¾„ (é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„)')
    
    parser.add_argument('--load-model', type=str, default=None,
                       help='åŠ è½½å·²è®­ç»ƒæ¨¡å‹çš„è·¯å¾„')
    
    parser.add_argument('--output-dir', type=str, default='results',
                       help='ç»“æœè¾“å‡ºç›®å½• (é»˜è®¤: results)')
    
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    
    return parser.parse_args()


def create_model(model_type: str):
    """åˆ›å»ºæŒ‡å®šç±»å‹çš„æ¨¡å‹"""
    if model_type == 'dtw':
        return DTWModel(config)
    elif model_type == 'vq':
        return VQModel(config)
    elif model_type == 'gmm':
        return GMMModel(config)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")


def train_model(model, global_train_files: Dict[str, List[str]], 
               model_type: str, save_path: str = None):
    """è®­ç»ƒæ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"å¼€å§‹è®­ç»ƒ {model_type.upper()} æ¨¡å‹")
    print(f"{'='*50}")
    
    start_time = time.time()
    
    # è®­ç»ƒæ¨¡å‹
    model.train(global_train_files)
    
    training_time = time.time() - start_time
    print(f"\n{model_type.upper()} æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f} ç§’")
    
    # ä¿å­˜æ¨¡å‹
    if save_path:
        model.save(save_path)
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    return model


def enroll_speakers(model, enroll_files: Dict[str, List[str]], model_type: str):
    """æ³¨å†Œè¯´è¯äºº"""
    print(f"\n{'='*50}")
    print(f"å¼€å§‹æ³¨å†Œè¯´è¯äºº ({model_type.upper()} æ¨¡å‹)")
    print(f"{'='*50}")

    start_time = time.time()
    total_speakers = len(enroll_files)
    total_files = sum(len(files) for files in enroll_files.values())

    print(f"éœ€è¦æ³¨å†Œ {total_speakers} ä¸ªè¯´è¯äººï¼Œå…± {total_files} ä¸ªæ–‡ä»¶")

    # ä½¿ç”¨tqdmæ˜¾ç¤ºæ³¨å†Œè¿›åº¦
    with tqdm(enroll_files.items(), desc=f"æ³¨å†Œè¯´è¯äºº({model_type.upper()})",
              unit="è¯´è¯äºº", ncols=100) as pbar:

        for speaker_id, files in pbar:
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            pbar.set_postfix({
                'å½“å‰è¯´è¯äºº': speaker_id[:10] + '...' if len(speaker_id) > 10 else speaker_id,
                'æ–‡ä»¶æ•°': len(files)
            })

            try:
                model.enroll(speaker_id, files)
            except Exception as e:
                tqdm.write(f"è­¦å‘Š: æ³¨å†Œè¯´è¯äºº {speaker_id} å¤±è´¥: {e}")
                continue

    enrollment_time = time.time() - start_time
    print(f"\nè¯´è¯äººæ³¨å†Œå®Œæˆï¼Œå…±æ³¨å†Œ {len(enroll_files)} ä¸ªè¯´è¯äºº")
    print(f"æ³¨å†Œè€—æ—¶: {enrollment_time:.2f} ç§’")

    return model


def test_model(model, test_files: Dict[str, List[str]], 
              model_type: str) -> Tuple[List[str], List[str], List[float], List[float]]:
    """æµ‹è¯•æ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"å¼€å§‹æµ‹è¯• {model_type.upper()} æ¨¡å‹")
    print(f"{'='*50}")
    
    true_labels = []
    predicted_labels = []
    target_scores = []
    imposter_scores = []
    
    start_time = time.time()

    # åˆ›å»ºæ‰€æœ‰æµ‹è¯•æ–‡ä»¶çš„åˆ—è¡¨ï¼Œç”¨äºè¿›åº¦æ¡
    all_test_files = []
    for true_speaker_id, files in test_files.items():
        for file_path in files:
            all_test_files.append((true_speaker_id, file_path))

    total_tests = len(all_test_files)
    print(f"æ€»å…±éœ€è¦æµ‹è¯• {total_tests} ä¸ªæ–‡ä»¶")

    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦æ¡
    with tqdm(all_test_files, desc=f"æµ‹è¯•{model_type.upper()}æ¨¡å‹",
              unit="æ–‡ä»¶", ncols=100) as pbar:

        for true_speaker_id, file_path in pbar:
            # æ›´æ–°è¿›åº¦æ¡æè¿°
            pbar.set_postfix({
                'å½“å‰è¯´è¯äºº': true_speaker_id[:8] + '...' if len(true_speaker_id) > 8 else true_speaker_id,
                'å·²å®Œæˆ': f"{len(true_labels)}/{total_tests}"
            })

            try:
                # è¯†åˆ«è¯´è¯äºº
                predicted_speaker_id, score = model.identify(file_path)

                true_labels.append(true_speaker_id)
                predicted_labels.append(predicted_speaker_id)

                # è®¡ç®—ç›®æ ‡åˆ†æ•°å’Œå†’åè€…åˆ†æ•°
                target_score = model.get_speaker_score(file_path, true_speaker_id)
                target_scores.append(target_score)

                # éšæœºé€‰æ‹©ä¸€ä¸ªå…¶ä»–è¯´è¯äººä½œä¸ºå†’åè€…
                other_speakers = [sid for sid in test_files.keys() if sid != true_speaker_id]
                if other_speakers:
                    import random
                    imposter_id = random.choice(other_speakers)
                    imposter_score = model.get_speaker_score(file_path, imposter_id)
                    imposter_scores.append(imposter_score)

            except Exception as e:
                # ä½¿ç”¨tqdm.writeæ¥åœ¨è¿›åº¦æ¡ä¸‹æ–¹æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
                tqdm.write(f"è­¦å‘Š: æµ‹è¯•æ–‡ä»¶å¤±è´¥ {os.path.basename(file_path)}: {e}")
                continue
    
    test_time = time.time() - start_time
    print(f"\næ¨¡å‹æµ‹è¯•å®Œæˆï¼Œå…±æµ‹è¯• {len(true_labels)} ä¸ªæ–‡ä»¶")
    print(f"æµ‹è¯•è€—æ—¶: {test_time:.2f} ç§’")
    
    return true_labels, predicted_labels, target_scores, imposter_scores


def save_results(results: Dict, output_dir: str, model_type: str):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    result_file = os.path.join(output_dir, f"{model_type}_results.txt")
    with open(result_file, 'w', encoding='utf-8') as f:
        f.write(f"{model_type.upper()} æ¨¡å‹è¯„ä¼°ç»“æœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"è¯†åˆ«å‡†ç¡®ç‡: {results.get('accuracy', 0):.2%}\n")
        if 'eer' in results:
            f.write(f"ç­‰é”™è¯¯ç‡(EER): {results['eer']:.2%}\n")
            f.write(f"EERå¯¹åº”é˜ˆå€¼: {results['eer_threshold']:.4f}\n")
    
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {result_file}")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()

    # è®¾ç½®è¯¦ç»†æ—¥å¿—
    if args.verbose:
        config.VERBOSE = True

    # éªŒè¯æ•°æ®è·¯å¾„
    data_path = args.data_path or config.VOXCELEB_PATH
    if not config.validate_paths():
        print(f"è­¦å‘Š: æ•°æ®é›†è·¯å¾„å¯èƒ½ä¸å­˜åœ¨: {data_path}")
        print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„VOXCELEB_PATHè®¾ç½®")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    print("ğŸ¯ å£°çº¹è¯†åˆ«ç³»ç»Ÿå¯åŠ¨")
    print(f"ğŸ“Š æ¨¡å‹ç±»å‹: {args.model.upper()}")
    print(f"ğŸ”§ è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {data_path}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {args.output_dir}")

    # åˆ›å»ºæ¨¡å‹
    model = create_model(args.model)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model}")

    # è®¡ç®—æ€»æ­¥éª¤æ•°
    total_steps = 0
    if args.mode in ['train', 'full']:
        total_steps += 3  # æ•°æ®åŠ è½½ã€è®­ç»ƒã€æ³¨å†Œ
    if args.mode in ['test', 'full']:
        total_steps += 2  # æµ‹è¯•ã€è¯„ä¼°

    current_step = 0
    
    # åŠ è½½æ•°æ®é›†
    if args.mode in ['train', 'full']:
        current_step += 1
        print(f"\nğŸ“‚ æ­¥éª¤ {current_step}/{total_steps}: åŠ è½½å’Œåˆ’åˆ†æ•°æ®é›†")
        global_train_files, enroll_files, test_files = get_dataset_split(data_path)
    
    # è®­ç»ƒé˜¶æ®µ
    if args.mode in ['train', 'full']:
        if args.load_model:
            current_step += 1
            print(f"\nğŸ”„ æ­¥éª¤ {current_step}/{total_steps}: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
            print(f"ä» {args.load_model} åŠ è½½æ¨¡å‹...")
            model.load(args.load_model)
        else:
            current_step += 1
            print(f"\nğŸ‹ï¸ æ­¥éª¤ {current_step}/{total_steps}: è®­ç»ƒæ¨¡å‹")
            model = train_model(model, global_train_files, args.model, args.save_model)

        # æ³¨å†Œè¯´è¯äºº
        current_step += 1
        print(f"\nğŸ‘¥ æ­¥éª¤ {current_step}/{total_steps}: æ³¨å†Œè¯´è¯äºº")
        model = enroll_speakers(model, enroll_files, args.model)
    
    # æµ‹è¯•é˜¶æ®µ
    if args.mode in ['test', 'full']:
        if args.mode == 'test' and args.load_model:
            current_step += 1
            print(f"\nğŸ”„ æ­¥éª¤ {current_step}/{total_steps}: åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹")
            print(f"ä» {args.load_model} åŠ è½½æ¨¡å‹...")
            model.load(args.load_model)
            # éœ€è¦é‡æ–°åŠ è½½æ•°æ®é›†ç”¨äºæµ‹è¯•
            print("é‡æ–°åŠ è½½æ•°æ®é›†ç”¨äºæµ‹è¯•...")
            _, enroll_files, test_files = get_dataset_split(data_path)

        # æ‰§è¡Œæµ‹è¯•
        current_step += 1
        print(f"\nğŸ§ª æ­¥éª¤ {current_step}/{total_steps}: æ‰§è¡Œæ¨¡å‹æµ‹è¯•")
        true_labels, predicted_labels, target_scores, imposter_scores = test_model(
            model, test_files, args.model)

        # è¯„ä¼°ç»“æœ
        current_step += 1
        print(f"\nğŸ“Š æ­¥éª¤ {current_step}/{total_steps}: è¯„ä¼°ç»“æœå’Œç”ŸæˆæŠ¥å‘Š")
        print(f"{'='*50}")
        print("ğŸ“ˆ æœ€ç»ˆè¯„ä¼°ç»“æœ")
        print(f"{'='*50}")

        results = print_evaluation_report(
            true_labels, predicted_labels, target_scores, imposter_scores)
        
        # ä¿å­˜ç»“æœ
        save_results(results, args.output_dir, args.model)
        
        # ç»˜åˆ¶å›¾è¡¨
        if target_scores and imposter_scores and len(true_labels) > 0:
            print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨...")
            det_curve_path = os.path.join(args.output_dir, f"{args.model}_det_curve.png")
            plot_det_curve(target_scores, imposter_scores,
                          f"{args.model.upper()} Model DET Curve", det_curve_path)

            score_dist_path = os.path.join(args.output_dir, f"{args.model}_score_distribution.png")
            plot_score_distribution(target_scores, imposter_scores,
                                  f"{args.model.upper()} Model Score Distribution",
                                  score_dist_path)
        else:
            print("\nâš ï¸  è·³è¿‡å›¾è¡¨ç”Ÿæˆï¼šæ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")

    print(f"\n{'='*60}")
    print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output_dir}")
    print(f"ğŸ”§ ä½¿ç”¨çš„æ¨¡å‹: {args.model.upper()}")
    
    if args.mode in ['test', 'full'] and 'results' in locals():
        if len(true_labels) > 0:
            if 'accuracy' in results:
                print(f"ğŸ¯ è¯†åˆ«å‡†ç¡®ç‡: {results['accuracy']:.2%}")
            if 'eer' in results:
                print(f"ğŸ“‰ ç­‰é”™è¯¯ç‡(EER): {results['eer']:.2%}")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸå¤„ç†çš„æµ‹è¯•æ ·æœ¬")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥æ•°æ®é›†è·¯å¾„é…ç½®")
            print("   2. é™ä½GMMç»„ä»¶æ•°é‡") 
            print("   3. å¢åŠ æ¯ä¸ªè¯´è¯äººçš„æ³¨å†Œæ–‡ä»¶æ•°é‡")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
